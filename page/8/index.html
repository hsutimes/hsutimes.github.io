<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 3.9.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Time</title>


    <meta name="description" content="blog">
<meta name="keywords" content="hsutimes">
<meta property="og:type" content="website">
<meta property="og:title" content="Time">
<meta property="og:url" content="https://blog.hsutimes.com/page/8/index.html">
<meta property="og:site_name" content="Time">
<meta property="og:description" content="blog">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://blog.hsutimes.com/images/og_image.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Time">
<meta name="twitter:description" content="blog">
<meta name="twitter:image" content="https://blog.hsutimes.com/images/og_image.png">
<meta name="twitter:site" content="https://twitter.com/times26740863">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134224598-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134224598-1');
</script>

    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    <script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Time" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" title="Download on GitHub" href="https://github.com/hsutimes/hsutimes.github.io">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main">
    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-25T08:34:54.000Z">2019-10-25</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    2 分钟 读完 (大约 354 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/10/25/windows-edb-mv/">windows.edb_mv</a>
            
        </h1>
        <div class="content">
            <h1 id="【Win10瘦身技巧】把索引文件Windows-edb移动到非系统盘"><a href="#【Win10瘦身技巧】把索引文件Windows-edb移动到非系统盘" class="headerlink" title="【Win10瘦身技巧】把索引文件Windows.edb移动到非系统盘"></a>【Win10瘦身技巧】把索引文件Windows.edb移动到非系统盘</h1><blockquote>
<p>先介绍Windows.edb是什么东东，很奇怪的后缀名哦。其实它就是Windows10为加快搜索速度而建立的索引文件，所以还是很有用的，但是看看它的体积，你就会觉得也太占系统盘的空间了。Windows.edb文件所在的路径为：</p>
</blockquote>
<figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\ProgramData\Microsoft\Search\Data\Applications\Windows</span><br></pre></td></tr></table></figure>

<p><img src="/images/2019/10/25/30949570-f702-11e9-84fc-111e5c1675c4.png" alt="image.png"></p>
<blockquote>
<p>虽然我们可以删除该文件，但正像前面说过的，它还是比较有用的（并且删除后，再次使用搜索功能后，它还会生成的），所以我们最好保留着它，但可以移动一下Windows.edb文件的位置，把它移动到非系统盘。方法如下：</p>
</blockquote>
<ol>
<li>在Win10任务栏的Cortana搜索框中输入“索引选项”，点击搜索结果中的“索引选项（控制面板）”打开“索引选项”窗口。</li>
<li>点击窗口底部的“高级”按钮，打开“高级选项”窗口。</li>
<li>在“索引位置”区域点击右下角的“选择新位置”按钮，为Windows.edb选择非系统盘的路径即可。最后点击“确定”，重启电脑后生效。</li>
</ol>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-24T13:19:23.000Z">2019-10-24</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 分钟 读完 (大约 448 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/10/24/lianhuafeng/">lianhuafeng</a>
            
        </h1>
        <div class="content">
            <h1 id="莲花峰（安徽境内山峰）"><a href="#莲花峰（安徽境内山峰）" class="headerlink" title="莲花峰（安徽境内山峰）"></a>莲花峰（安徽境内山峰）</h1><blockquote>
<p>莲花峰，是黄山风景区境内第一高峰，为36大峰之首，海拔1864.8米。位于登山步道玉屏楼到鳌鱼峰之间。莲花峰登峰盘道5里，相对高度110米。1997年，莲花沟开辟500米登山新道，由蹬道、栈桥、观景台等组成。</p>
</blockquote>
<blockquote>
<p>莲花峰峻峭高耸，气势雄伟。因主峰突兀，小峰簇拥，俨若新莲初开，仰天怒放，故名“莲花峰”。“登峰起步缓坡称“莲梗”，中间穿过四个石洞，古人称“莲孔”。洞穴陡立，游人叠级而上，如在莲孔中穿行，恰似“倾曲作蚁旋出花萼中”。沿途风光奇绝，峰壁间有“真好造化”、“非人间也”、“名不虚传”、“天海奇观”等摩崖题刻。峰下有莲花洞、莲花源。</p>
</blockquote>
<blockquote>
<p>明代吴怅曾有诗赞曰：“一种青莲吐绛霞，亭亭玉立净无瑕。遥看天际浮云卷，露出峰顶十丈花。”清代吴梦印亦有诗云：“莲峰秀拔迥称尊，凡欲高呼达帝阍。举目江山如带砺，低头峦蚰似儿孙。风生绝献应回雁，日落悬岩不度猿。翠影岚光千万状，我虽能到未能言。”连接莲花岭和莲花峰的是一条长达一公里半的蜿蜒小道，在到达峰顶前要过四个洞穴。<br>莲花峰上既有许多或似飞龙或似双龙的松树，也有著名的黄山杜鹃花 [1]  。</p>
</blockquote>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-22T13:17:32.000Z">2019-10-22</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 分钟 读完 (大约 688 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/10/22/weilibipei/">weilibipei</a>
            
        </h1>
        <div class="content">
            <h1 id="违例匹配"><a href="#违例匹配" class="headerlink" title="违例匹配"></a>违例匹配</h1><p>“掷”出一个违例后，违例控制系统会按当初编写的顺序搜索“最接近”的控制器。一旦找到相符的控制器，就认为违例已得到控制，不再进行更多的搜索工作。</p>
<p>在违例和它的控制器之间，并不需要非常精确的匹配。一个衍生类对象可与基础类的一个控制器相配，如下例所示：</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">//: Human.java</span><br><span class="line">// Catching Exception Hierarchies</span><br><span class="line"></span><br><span class="line">class Annoyance extends Exception &#123;&#125;</span><br><span class="line">class Sneeze extends Annoyance &#123;&#125;</span><br><span class="line"></span><br><span class="line">public class Human &#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      throw new Sneeze();</span><br><span class="line">    &#125; catch(Sneeze s) &#123;</span><br><span class="line">      System.out.println(&quot;Caught Sneeze&quot;);</span><br><span class="line">    &#125; catch(Annoyance a) &#123;</span><br><span class="line">      System.out.println(&quot;Caught Annoyance&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; ///:~</span><br></pre></td></tr></table></figure>

<p>Sneeze违例会被相符的第一个catch从句捕获。当然，这只是第一个。然而，假如我们删除第一个catch从句：</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">  throw new Sneeze();</span><br><span class="line">&#125; catch(Annoyance a) &#123;</span><br><span class="line">  System.out.println(&quot;Caught Annoyance&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>那么剩下的catch从句依然能够工作，因为它捕获的是Sneeze的基础类。换言之，catch(Annoyance e)能捕获一个Annoyance以及从它衍生的任何类。这一点非常重要，因为一旦我们决定为一个方法添加更多的违例，而且它们都是从相同的基础类继承的，那么客户程序员的代码就不需要更改。至少能够假定它们捕获的是基础类。</p>
<p>若将基础类捕获从句置于第一位，试图“屏蔽”衍生类违例，就象下面这样：</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">  throw new Sneeze();</span><br><span class="line">&#125; catch(Annoyance a) &#123;</span><br><span class="line">  System.out.println(&quot;Caught Annoyance&quot;);</span><br><span class="line">&#125; catch(Sneeze s) &#123;</span><br><span class="line">  System.out.println(&quot;Caught Sneeze&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>则编译器会产生一条出错消息，因为它发现永远不可能抵达Sneeze捕获从句。</p>
<p>9.8.1 违例准则</p>
<p>用违例做下面这些事情：</p>
<p>(1) 解决问题并再次调用造成违例的方法。</p>
<p>(2) 平息事态的发展，并在不重新尝试方法的前提下继续。</p>
<p>(3) 计算另一些结果，而不是希望方法产生的结果。</p>
<p>(4) 在当前环境中尽可能解决问题，以及将相同的违例重新“掷”出一个更高级的环境。</p>
<p>(5) 在当前环境中尽可能解决问题，以及将不同的违例重新“掷”出一个更高级的环境。</p>
<p>(6) 中止程序执行。</p>
<p>(7) 简化编码。若违例方案使事情变得更加复杂，那就会令人非常烦恼，不如不用。</p>
<p>(8) 使自己的库和程序变得更加安全。这既是一种“短期投资”（便于调试），也是一种“长期投资”（改善应用程序的健壮性）</p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-21T14:32:22.000Z">2019-10-21</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 分钟 读完 (大约 1095 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/10/21/computer-vision-weekly-news-20191003/">computer-vision-weekly-news-20191003</a>
            
        </h1>
        <div class="content">
            <h1 id="计算机视觉开源周报20191003期"><a href="#计算机视觉开源周报20191003期" class="headerlink" title="计算机视觉开源周报20191003期"></a>计算机视觉开源周报20191003期</h1><blockquote>
<p>总结了过去一周CV领域的最新开源代码，发现本周出现多份很有价值的高质量、重量级工作，比如致力于使得图卷积网络更深的DeepGCNs、Mask引导的注意力网络大大改进了遮挡行人重识别、格灵深瞳轻量级人脸识别比赛冠军模型VarGFaceNet、比LSTM更优的新RNN模型IndRNN、还有异常强大的字符级文本识别CharNet。</p>
</blockquote>
<p><img src="/images/2019/10/21/f3b59040-f40f-11e9-89e6-e714074eda99.png" alt="image.png"></p>
<ul>
<li><p>一种web运行的半自动图像标注的灵活框架LOST（Label Objects and Save Time）<br>LOST: A flexible framework for semi-automatic image annotation<br>Jonas Jäger, Gereon Reus, Joachim Denzler, Viviane Wolff, Klaus Fricke-Neuderth<br><a href="https://arxiv.org/abs/1910.07486v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07486v1</a><br><a href="https://github.com/l3p-cv/lost" target="_blank" rel="noopener">https://github.com/l3p-cv/lost</a></p>
</li>
<li><p>对抗表示学习中的全局最优化问题<br>On the Global Optima of Kernelized Adversarial Representation Learning<br>Bashir Sadeghi, Runyi Yu, Vishnu Naresh Boddeti<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.07423v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07423v1</a><br><a href="https://github.com/human-analysis/Kernel-ARL" target="_blank" rel="noopener">https://github.com/human-analysis/Kernel-ARL</a></p>
</li>
<li><p>学习泛化的全尺度表示，用于人员重识别，模型更小，精度更优<br>Learning Generalisable Omni-Scale Representations for Person Re-Identification<br>Kaiyang Zhou, Xiatian Zhu, Yongxin Yang, Andrea Cavallaro, Tao Xiang<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.06827v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.06827v1</a><br><a href="https://github.com/KaiyangZhou/deep-person-reid" target="_blank" rel="noopener">https://github.com/KaiyangZhou/deep-person-reid</a></p>
</li>
<li><p>将ResNet和DenseNet引入到图卷积网络中，可以训练更深（达112层）的GCN，在多个任务中达到了更高的精度。<br>DeepGCNs: Making GCNs Go as Deep as CNNs<br>Guohao Li, Matthias Müller, Guocheng Qian, Itzel C. Delgadillo, Abdulellah Abualshour, Ali Thabet, Bernard Ghanem<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.06849v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.06849v1</a><br><a href="https://github.com/lightaime/deep_gcns_torch" target="_blank" rel="noopener">https://github.com/lightaime/deep_gcns_torch</a><br><a href="https://github.com/lightaime/deep_gcns" target="_blank" rel="noopener">https://github.com/lightaime/deep_gcns</a></p>
</li>
<li><p>训练智能体玩“躲猫猫”游戏<br>Visual Hide and Seek<br>Boyuan Chen, Shuran Song, Hod Lipson, Carl Vondrick<br><a href="https://arxiv.org/abs/1910.07882v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07882v1</a><br><a href="http://www.cs.columbia.edu/~bchen/visualhideseek/" target="_blank" rel="noopener">http://www.cs.columbia.edu/~bchen/visualhideseek/</a></p>
</li>
<li><p>掩膜引导的注意力网络，用于遮挡严重的行人检测，在多个数据集实现了更高的最好精度。CityPersons提升9.5%，Caltech提升5.0%。<br>Mask-Guided Attention Network for Occluded Pedestrian Detection<br>Yanwei Pang, Jin Xie, Muhammad Haris Khan, Rao Muhammad Anwer, Fahad Shahbaz Khan, Ling Shao<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.06160v2" target="_blank" rel="noopener">https://arxiv.org/abs/1910.06160v2</a><br><a href="https://github.com/Leotju/MGAN" target="_blank" rel="noopener">https://github.com/Leotju/MGAN</a></p>
</li>
<li><p>一种几何启发的卷积操作，有效提升了消失点检测<br>NeurVPS: Neural Vanishing Point Scanning via Conic Convolution<br>Yichao Zhou, Haozhi Qi, Jingwei Huang, Yi Ma<br><a href="https://arxiv.org/abs/1910.06316v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.06316v1</a><br><a href="https://github.com/zhou13/neurvps" target="_blank" rel="noopener">https://github.com/zhou13/neurvps</a></p>
</li>
<li><p>单次神经架构搜索，基于自我评估模版网络，在CIFAR和ImageNet数据集达到最先进的性能<br>One-Shot Neural Architecture Search via Self-Evaluated Template Network<br>Xuanyi Dong, Yi Yang<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.05733v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.05733v1</a><br><a href="https://github.com/D-X-Y/NAS-Projects" target="_blank" rel="noopener">https://github.com/D-X-Y/NAS-Projects</a></p>
</li>
<li><p>学习鉴别特征，用于非监督域适应<br>Drop to Adapt: Learning Discriminative Features for Unsupervised Domain Adaptation<br>Seungmin Lee, Dongwan Kim, Namil Kim, Seong-Gyun Jeong<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.05562v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.05562v1</a><br><a href="https://github.com/postBG/DTA.pytorch" target="_blank" rel="noopener">https://github.com/postBG/DTA.pytorch</a></p>
</li>
<li><p>可变组卷积神经网络，可以支持大规模人脸识别，同时减少计算成本和参数。获得格灵深瞳轻量级人脸识别挑战赛冠军！<br>VarGFaceNet: An Efficient Variable Group Convolutional Neural Network for Lightweight Face Recognition<br>Mengjia Yan, Mengao Zhao, Zining Xu, Qian Zhang, Guoli Wang, Zhizhong Su<br>ICCV 2019 Workshop<br><a href="https://arxiv.org/abs/1910.04985v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.04985v1</a><br><a href="https://github.com/zma-c-137/VarGFaceNet" target="_blank" rel="noopener">https://github.com/zma-c-137/VarGFaceNet</a></p>
</li>
<li><p>发明一种称为Hadamard乘积的递归连接，构建了独立递归神经网络（IndRNN），其中同一层中的神经元彼此独立并且跨层连接。<br>IndRNN可有效替代LSTM，精度更高的同时，速度是其10倍！<br>Deep Independently Recurrent Neural Network (IndRNN)<br>Shuai Li, Wanqing Li, Chris Cook, Yanbo Gao, Ce Zhu<br><a href="https://arxiv.org/abs/1910.06251v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.06251v1</a><br><a href="https://github.com/Sunnydreamrain/IndRNN_pytorch" target="_blank" rel="noopener">https://github.com/Sunnydreamrain/IndRNN_pytorch</a></p>
</li>
<li><p>一种以字符为基本单元的单阶段文本检测识别网络，在三个标准基准上对CharNet结果显示，其结果以最先进的结果大大领先之前的算法，比如ICDAR 2015上从65.33％改进到71.08％，TotalText上从54.0％跃升至69.23％。<br>Convolutional Character Networks<br>Linjie Xing, Zhi Tian, Weilin Huang, Matthew R. Scott<br>ICCV 2019<br><a href="https://arxiv.org/abs/1910.07954v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07954v1</a><br><a href="https://github.com/MalongTech/research-charnet" target="_blank" rel="noopener">https://github.com/MalongTech/research-charnet</a></p>
</li>
<li><p>基于语音指令实现的自动驾驶<br>Conditional Driving from Natural Language Instructions<br>Junha Roh, Chris Paxton, Andrzej Pronobis, Ali Farhadi, Dieter Fox<br>CoRL 2019<br><a href="https://arxiv.org/abs/1910.07615v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07615v1</a><br><a href="https://sites.google.com/view/language-grounded-driving" target="_blank" rel="noopener">https://sites.google.com/view/language-grounded-driving</a></p>
</li>
<li><p>医学图像域适应 | 提出了一种新型的无监督域自适应框架，称为协作特征集合自适应（CFEA），改进了眼底图像分割的精度<br>CFEA: Collaborative Feature Ensembling Adaptation for Domain Adaptation in Unsupervised Optic Disc and Cup Segmentation<br>Peng Liu, Bin Kong, Zhongyu Li, Shaoting Zhang, Ruogu Fang<br>MICCAI 2019<br><a href="https://arxiv.org/abs/1910.07638v1" target="_blank" rel="noopener">https://arxiv.org/abs/1910.07638v1</a><br><a href="https://github.com/cswin/AWC" target="_blank" rel="noopener">https://github.com/cswin/AWC</a></p>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-20T08:48:58.000Z">2019-10-20</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    16 分钟 读完 (大约 2446 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/10/20/PLMpapers/">PLMpapers</a>
            
        </h1>
        <div class="content">
            <h1 id="PLMpapers"><a href="#PLMpapers" class="headerlink" title="PLMpapers"></a>PLMpapers</h1><p>Contributed by <a href="https://bakser.github.io/" target="_blank" rel="noopener">Xiaozhi Wang</a> and <a href="https://github.com/zzy14" target="_blank" rel="noopener">Zhengyan Zhang</a>.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Pre-trained Languge Model (PLM) is a very popular topic in NLP. In this repo, we list some representative work on PLM and show their relationship with a diagram. Feel free to distribute or use it! <a href="https://github.com/thunlp/PLMpapers/blob/master/PLMfamily.pptx" target="_blank" rel="noopener">Here</a> you can get the source PPT file of the diagram if you want to use it in your presentation.</p>
<p><img src="/images/2019/10/20/3f634050-f316-11e9-b017-0b2638cf8a9a.png" alt="image.png"></p>
<p>Corrections and suggestions are welcomed. </p>
<p>We also released <a href="https://github.com/thunlp/OpenCLaP" target="_blank" rel="noopener">OpenCLap</a>, an open-source Chinese language pre-trained model zoo. Welcome to try it.</p>
<h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><ol>
<li><strong>Semi-supervised Sequence Learning</strong>. <em>Andrew M. Dai, Quoc V. Le</em>. NIPS 2015. [<a href="https://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>context2vec: Learning Generic Context Embedding with Bidirectional LSTM</strong>. <em>Oren Melamud, Jacob Goldberger, Ido Dagan</em>. CoNLL 2016. [<a href="https://www.aclweb.org/anthology/K16-1006.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="http://u.cs.biu.ac.il/~nlp/resources/downloads/context2vec/" target="_blank" rel="noopener">project</a>] (<strong>context2vec</strong>)</li>
<li><strong>Unsupervised Pretraining for Sequence to Sequence Learning</strong>. <em>Prajit Ramachandran, Peter J. Liu, Quoc V. Le</em>. EMNLP 2017. [<a href="https://arxiv.org/pdf/1611.02683.pdf" target="_blank" rel="noopener">pdf</a>] (<strong>Pre-trained seq2seq</strong>)`</li>
<li><strong>Deep contextualized word representations</strong>. <em>Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee and Luke Zettlemoyer</em>. NAACL 2018. [<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://allennlp.org/elmo" target="_blank" rel="noopener">project</a>] (<strong>ELMo</strong>)</li>
<li><strong>Universal Language Model Fine-tuning for Text Classification</strong>. <em>Jeremy Howard and Sebastian Ruder</em>. ACL 2018. [<a href="https://www.aclweb.org/anthology/P18-1031" target="_blank" rel="noopener">pdf</a>] [<a href="http://nlp.fast.ai/category/classification.html" target="_blank" rel="noopener">project</a>] (<strong>ULMFiT</strong>)</li>
<li><strong>Improving Language Understanding by Generative Pre-Training</strong>. <em>Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever</em>. Preprint. [<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://openai.com/blog/language-unsupervised/" target="_blank" rel="noopener">project</a>] (<strong>GPT</strong>)</li>
<li><strong>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</strong>. <em>Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova</em>. NAACL 2019. [<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>Language Models are Unsupervised Multitask Learners</strong>. <em>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever</em>. Preprint. [<a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/openai/gpt-2" target="_blank" rel="noopener">code</a>] (<strong>GPT-2</strong>)</li>
<li><strong>ERNIE: Enhanced Language Representation with Informative Entities</strong>. <em>Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun and Qun Liu</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1139" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/thunlp/ERNIE" target="_blank" rel="noopener">code &amp; model</a>] (<strong>ERNIE (Tsinghua)</strong> )</li>
<li><strong>ERNIE: Enhanced Representation through Knowledge Integration</strong>. <em>Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian and Hua Wu</em>. Preprint. [<a href="https://arxiv.org/pdf/1904.09223.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/PaddlePaddle/ERNIE/tree/develop/ERNIE" target="_blank" rel="noopener">code</a>] (<strong>ERNIE (Baidu)</strong> )</li>
<li><strong>Defending Against Neural Fake News</strong>. <em>Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi</em>. NeurIPS 2019. [<a href="https://arxiv.org/pdf/1905.12616.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://rowanzellers.com/grover/" target="_blank" rel="noopener">project</a>] (<strong>Grover</strong>)</li>
<li><strong>Cross-lingual Language Model Pretraining</strong>. <em>Guillaume Lample, Alexis Conneau</em>. NeurIPS 2019. [<a href="https://arxiv.org/pdf/1901.07291.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/facebookresearch/XLM" target="_blank" rel="noopener">code &amp; model</a>] (<strong>XLM</strong>)</li>
<li><strong>Multi-Task Deep Neural Networks for Natural Language Understanding</strong>. <em>Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1441" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/namisan/mt-dnn" target="_blank" rel="noopener">code &amp; model</a>] (<strong>MT-DNN</strong>)</li>
<li><strong>MASS: Masked Sequence to Sequence Pre-training for Language Generation</strong>. <em>Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu</em>. ICML 2019. [<a href="https://arxiv.org/pdf/1905.02450.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/microsoft/MASS" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>Unified Language Model Pre-training for Natural Language Understanding and Generation</strong>. <em>Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon</em>. Preprint. [<a href="https://arxiv.org/pdf/1905.03197.pdf" target="_blank" rel="noopener">pdf</a>] (<strong>UniLM</strong>)</li>
<li><strong>XLNet: Generalized Autoregressive Pretraining for Language Understanding</strong>. <em>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le</em>. NeurIPS 2019. [<a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/zihangdai/xlnet" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>RoBERTa: A Robustly Optimized BERT Pretraining Approach</strong>. <em>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov</em>. Preprint. [<a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>SpanBERT: Improving Pre-training by Representing and Predicting Spans</strong>. <em>Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, Omer Levy</em>. Preprint. [<a href="https://arxiv.org/pdf/1907.10529.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/facebookresearch/SpanBERT" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>Knowledge Enhanced Contextual Word Representations</strong>. <em>Matthew E. Peters, Mark Neumann, Robert L. Logan IV, Roy Schwartz, Vidur Joshi, Sameer Singh, Noah A. Smith</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.04164.pdf" target="_blank" rel="noopener">pdf</a>] (<strong>KnowBert</strong>) </li>
<li><strong>VisualBERT: A Simple and Performant Baseline for Vision and Language</strong>. <em>Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang</em>. Preprint. [<a href="https://arxiv.org/pdf/1908.03557.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/uclanlp/visualbert" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</strong>. <em>Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee</em>. NeurIPS 2019. [<a href="https://arxiv.org/pdf/1908.02265.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/jiasenlu/vilbert_beta" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>VideoBERT: A Joint Model for Video and Language Representation Learning</strong>. <em>Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, Cordelia Schmid</em>. ICCV 2019. [<a href="https://arxiv.org/pdf/1904.01766.pdf" target="_blank" rel="noopener">pdf</a>] </li>
<li><strong>LXMERT: Learning Cross-Modality Encoder Representations from Transformers</strong>. <em>Hao Tan, Mohit Bansal</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.07490.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/airsplay/lxmert" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>VL-BERT: Pre-training of Generic Visual-Linguistic Representations</strong>. <em>Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai</em>. Preprint. [<a href="https://arxiv.org/pdf/1908.08530.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training</strong>. <em>Gen Li, Nan Duan, Yuejian Fang, Ming Gong, Daxin Jiang, Ming Zhou</em>. Preprint. [<a href="https://arxiv.org/pdf/1908.06066.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>K-BERT: Enabling Language Representation with Knowledge Graph</strong>. <em>Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, Ping Wang</em>. Preprint. [<a href="https://arxiv.org/pdf/1909.07606.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Fusion of Detected Objects in Text for Visual Question Answering</strong>. <em>Chris Alberti, Jeffrey Ling, Michael Collins, David Reitter</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.05054.pdf" target="_blank" rel="noopener">pdf</a>] (<strong>B2T2</strong>)</li>
<li><strong>Contrastive Bidirectional Transformer for Temporal Representation Learning</strong>. <em>Chen Sun, Fabien Baradel, Kevin Murphy, Cordelia Schmid</em>. Preprint. [<a href="https://arxiv.org/pdf/1906.05743.pdf" target="_blank" rel="noopener">pdf</a>] (<strong>CBT</strong>)</li>
<li><strong>ERNIE 2.0: A Continual Pre-training Framework for Language Understanding</strong>. <em>Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, Haifeng Wang</em>. Preprint. [<a href="https://arxiv.org/pdf/1907.12412v1.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/PaddlePaddle/ERNIE/blob/develop/README.md" target="_blank" rel="noopener">code</a>] </li>
<li><strong>75 Languages, 1 Model: Parsing Universal Dependencies Universally</strong>. <em>Dan Kondratyuk, Milan Straka</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1904.02099.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/hyperparticle/udify" target="_blank" rel="noopener">code &amp; model</a>] (<strong>UDify</strong>)</li>
<li><strong>Pre-Training with Whole Word Masking for Chinese BERT</strong>. <em>Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Ziqing Yang, Shijin Wang, Guoping Hu</em>. Preprint. [<a href="https://arxiv.org/pdf/1906.08101.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/ymcui/Chinese-BERT-wwm/blob/master/README_EN.md" target="_blank" rel="noopener">code &amp; model</a>] (<strong>Chinese-BERT-wwm</strong>)</li>
<li><strong>UNITER: Learning UNiversal Image-TExt Representations</strong>. <em>Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, Jingjing Liu</em>. Preprint. [<a href="https://arxiv.org/pdf/1909.11740.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>HUBERT Untangles BERT to Improve Transfer across NLP Tasks</strong>. <em>Anonymous authors</em>. ICLR 2020 under review. [<a href="https://openreview.net/pdf?id=HJxnM1rFvr" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>MultiFiT: Efficient Multi-lingual Language Model Fine-tuning</strong>.  <em>Julian Eisenschlos, Sebastian Ruder, Piotr Czapla, Marcin Kardas, Sylvain Gugger, Jeremy Howard</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.04761.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="http://nlp.fast.ai/classification/2019/09/10/multifit.html" target="_blank" rel="noopener">code &amp; model</a>]</li>
</ol>
<h3 id="Knowledge-Distillation-amp-Model-Compression"><a href="#Knowledge-Distillation-amp-Model-Compression" class="headerlink" title="Knowledge Distillation &amp; Model Compression"></a>Knowledge Distillation &amp; Model Compression</h3><ol>
<li><strong>TinyBERT: Distilling BERT for Natural Language Understanding</strong>. <em>Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, Qun Liu</em>. Preprint. [<a href="https://arxiv.org/pdf/1909.10351v2.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Distilling Task-Specific Knowledge from BERT into Simple Neural Networks</strong>. <em>Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, Jimmy Lin</em>. Preprint. [<a href="https://arxiv.org/pdf/1903.12136.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Patient Knowledge Distillation for BERT Model Compression</strong>. <em>Siqi Sun, Yu Cheng, Zhe Gan, Jingjing Liu</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.09355.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/intersun/PKD-for-BERT-Model-Compression" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Model Compression with Multi-Task Knowledge Distillation for Web-scale Question Answering System</strong>. <em>Ze Yang, Linjun Shou, Ming Gong, Wutao Lin, Daxin Jiang</em>. Preprint. [<a href="https://arxiv.org/pdf/1904.09636.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>PANLP at MEDIQA 2019: Pre-trained Language Models, Transfer Learning and Knowledge Distillation</strong>. <em>Wei Zhu, Xiaofeng Zhou, Keqiang Wang, Xun Luo, Xiepeng Li, Yuan Ni, Guotong Xie</em>. The 18th BioNLP workshop. [<a href="https://www.aclweb.org/anthology/W19-5040" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding</strong>. <em>Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao</em>. Preprint. [<a href="https://arxiv.org/pdf/1904.09482.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/namisan/mt-dnn" target="_blank" rel="noopener">code &amp; model</a>]</li>
<li><strong>Well-Read Students Learn Better: The Impact of Student Initialization on Knowledge Distillation</strong>. <em>Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova</em>. Preprint. [<a href="https://arxiv.org/pdf/1908.08962.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Small and Practical BERT Models for Sequence Labeling</strong>. <em>Henry Tsai, Jason Riesa, Melvin Johnson, Naveen Arivazhagan, Xin Li, Amelia Archer</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.00100.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT</strong>. <em>Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W. Mahoney, Kurt Keutzer</em>. Preprint. [<a href="https://arxiv.org/pdf/1909.05840.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</strong>.  <em>Anonymous authors</em>. ICLR 2020 under review. [<a href="https://openreview.net/pdf?id=H1eA7AEtvS" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Extreme Language Model Compression with Optimal Subwords and Shared Projections</strong>. <em>Sanqiang Zhao, Raghav Gupta, Yang Song, Denny Zhou</em>. Preprint. [<a href="https://arxiv.org/pdf/1909.11687" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</strong>. <em>Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf</em>. Preprint. [<a href="https://arxiv.org/pdf/1910.01108" target="_blank" rel="noopener">pdf</a>]</li>
</ol>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><ol>
<li><strong>Revealing the Dark Secrets of BERT</strong>. <em>Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky</em>. EMNLP 2019. [<a href="https://arxiv.org/abs/1908.08593" target="_blank" rel="noopener">pdf</a>] </li>
<li><strong>How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations</strong>. <em>Betty van Aken, Benjamin Winter, Alexander Löser, Felix A. Gers</em>. CIKM 2019. [<a href="https://arxiv.org/pdf/1909.04925.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Are Sixteen Heads Really Better than One?</strong>. <em>Paul Michel, Omer Levy, Graham Neubig</em>. Preprint. [<a href="https://arxiv.org/pdf/1905.10650.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/pmichel31415/are-16-heads-really-better-than-1" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment</strong>. <em>Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits</em>. Preprint. [<a href="https://arxiv.org/pdf/1907.11932.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/jind11/TextFooler" target="_blank" rel="noopener">code</a>]</li>
<li><strong>BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model</strong>. <em>Alex Wang, Kyunghyun Cho</em>. NeuralGen 2019. [<a href="https://arxiv.org/pdf/1902.04094.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/nyu-dl/bert-gen" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Linguistic Knowledge and Transferability of Contextual Representations</strong>. <em>Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E. Peters, Noah A. Smith</em>. NAACL 2019. [<a href="https://www.aclweb.org/anthology/N19-1112" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>What Does BERT Look At? An Analysis of BERT’s Attention</strong>. <em>Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning</em>. BlackBoxNLP 2019. [<a href="https://arxiv.org/pdf/1906.04341.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/clarkkev/attention-analysis" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Open Sesame: Getting Inside BERT’s Linguistic Knowledge</strong>. <em>Yongjie Lin, Yi Chern Tan, Robert Frank</em>. BlackBoxNLP 2019. [<a href="https://arxiv.org/pdf/1906.01698.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/yongjie-lin/bert-opensesame" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Analyzing the Structure of Attention in a Transformer Language Model</strong>. <em>Jesse Vig, Yonatan Belinkov</em>. BlackBoxNLP 2019. [<a href="https://arxiv.org/pdf/1906.04284.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Blackbox meets blackbox: Representational Similarity and Stability Analysis of Neural Language Models and Brains</strong>. <em>Samira Abnar, Lisa Beinborn, Rochelle Choenni, Willem Zuidema</em>. BlackBoxNLP 2019. [<a href="https://arxiv.org/pdf/1906.01539.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>BERT Rediscovers the Classical NLP Pipeline</strong>. <em>Ian Tenney, Dipanjan Das, Ellie Pavlick</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1452" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>How multilingual is Multilingual BERT?</strong>. <em>Telmo Pires, Eva Schlinger, Dan Garrette</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1493" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>What Does BERT Learn about the Structure of Language?</strong>. <em>Ganesh Jawahar, Benoît Sagot, Djamé Seddah</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1356" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT</strong>. <em>Shijie Wu, Mark Dredze</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1904.09077.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings</strong>. <em>Kawin Ethayarajh</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.00512.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Probing Neural Network Comprehension of Natural Language Arguments</strong>. <em>Timothy Niven, Hung-Yu Kao</em>. ACL 2019. [<a href="https://www.aclweb.org/anthology/P19-1459" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/IKMLab/arct2" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Universal Adversarial Triggers for Attacking and Analyzing NLP</strong>. <em>Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.07125.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/Eric-Wallace/universal-triggers" target="_blank" rel="noopener">code</a>]</li>
<li><strong>The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives</strong>. <em>Elena Voita, Rico Sennrich, Ivan Titov</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.01380.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Do NLP Models Know Numbers? Probing Numeracy in Embeddings</strong>. <em>Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.07940.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Investigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs</strong>. <em>Alex Warstadt, Yu Cao, Ioana Grosu, Wei Peng, Hagen Blix, Yining Nie, Anna Alsop, Shikha Bordia, Haokun Liu, Alicia Parrish, Sheng-Fu Wang, Jason Phang, Anhad Mohananey, Phu Mon Htut, Paloma Jeretič, Samuel R. Bowman</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1909.02597.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/alexwarstadt/data_generation" target="_blank" rel="noopener">code</a>]</li>
<li><strong>Visualizing and Understanding the Effectiveness of BERT</strong>. <em>Yaru Hao, Li Dong, Furu Wei, Ke Xu</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.05620.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Visualizing and Measuring the Geometry of BERT</strong>. <em>Andy Coenen, Emily Reif, Ann Yuan, Been Kim, Adam Pearce, Fernanda Viégas, Martin Wattenberg</em>. NeurIPS 2019. [<a href="https://arxiv.org/pdf/1906.02715.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>On the Validity of Self-Attention as Explanation in Transformer Models</strong>. <em>Gino Brunner, Yang Liu, Damián Pascual, Oliver Richter, Roger Wattenhofer</em>. Preprint. [<a href="https://arxiv.org/pdf/1908.04211.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Transformer Dissection: An Unified Understanding for Transformer’s Attention via the Lens of Kernel</strong>. <em>Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov</em>. EMNLP 2019. [<a href="https://arxiv.org/pdf/1908.11775.pdf" target="_blank" rel="noopener">pdf</a>]</li>
<li><strong>Language Models as Knowledge Bases?</strong> <em>Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H. Miller, Sebastian Riedel</em>. EMNLP 2019, [<a href="https://arxiv.org/pdf/1909.01066.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/facebookresearch/LAMA" target="_blank" rel="noopener">code</a>]</li>
<li><strong>To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks</strong>. <em>Matthew E. Peters, Sebastian Ruder, Noah A. Smith</em>. RepL4NLP 2019, [<a href="https://www.aclweb.org/anthology/W19-4302.pdf" target="_blank" rel="noopener">pdf</a>]</li>
</ol>
<h2 id="Tutorial-amp-Resource"><a href="#Tutorial-amp-Resource" class="headerlink" title="Tutorial &amp; Resource"></a>Tutorial &amp; Resource</h2><ol>
<li><strong>Transfer Learning in Natural Language Processing</strong>. <em>Sebastian Ruder, Matthew E. Peters, Swabha Swayamdipta, Thomas Wolf</em>. NAACL 2019. [<a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit?usp=sharing" target="_blank" rel="noopener">slides</a>] </li>
<li><strong>Transformers: State-of-the-art Natural Language Processing</strong>. <em>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Jamie Brew</em>. Preprint. [<a href="https://arxiv.org/pdf/1910.03771.pdf" target="_blank" rel="noopener">pdf</a>] [<a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener">code</a>]</li>
</ol>

        </div>
        
        
        
    </div>
</div>









    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous">
            <a class="is-flex-grow has-text-black-ter" href="/page/7/">上一页</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/page/9/">下一页</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link has-text-black-ter" href="/">1</a></li>
            
            <li><span class="pagination-ellipsis has-text-black-ter">&hellip;</span></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/page/7/">7</a></li>
            
            <li><a class="pagination-link is-current" href="/page/8/">8</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/page/9/">9</a></li>
            
            <li><span class="pagination-ellipsis has-text-black-ter">&hellip;</span></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/page/21/">21</a></li>
            
        </ul>
    </nav>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left is-sticky">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="is-rounded" src="https://hsutimes.github.io/images/16530d7f26a413c2.png" alt="Time">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Time
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        Developer
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Earth, Solar System</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            103
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            6
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            128
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/hsutimes" target="_blank">
                关注我</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Github" href="https://github.com/hsutimes">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Twitter" href="https://twitter.com/times26740863">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            链接
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://github.com/hsutimes" target="_blank">
                    <span class="level-left">
                        <span class="level-item">PPOffice</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://hsutimes.club" target="_blank">
                    <span class="level-left">
                        <span class="level-item">Time</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">hsutimes.club</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                分类
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/Others/">
            <span class="level-start">
                <span class="level-item">Others</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/人工智能/">
            <span class="level-start">
                <span class="level-item">人工智能</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">7</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/文章/">
            <span class="level-start">
                <span class="level-item">文章</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">79</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/生活/">
            <span class="level-start">
                <span class="level-item">生活</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">7</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/笔试/">
            <span class="level-start">
                <span class="level-item">笔试</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/算法/">
            <span class="level-start">
                <span class="level-item">算法</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">7</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen is-sticky">
        
            
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2019/11/23/flash-crack/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/23/c7b6b780-0e04-11ea-92ef-97d48f79b822.png" alt="Flash的破解与加密(附flash破解工具)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-23T15:19:24.000Z">2019-11-23</time></div>
                    <a href="/2019/11/23/flash-crack/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Flash的破解与加密(附flash破解工具)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/22/inspire-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/22/55e1b850-0d12-11ea-bfb0-97cf8ad096e4.png" alt="INSPIRE 2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-22T10:24:48.000Z">2019-11-22</time></div>
                    <a href="/2019/11/22/inspire-2/" class="title has-link-black-ter is-size-6 has-text-weight-normal">INSPIRE 2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/生活/">生活</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/21/gitpod/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/21/1fa463f0-0c22-11ea-b732-8394f2c36e81.png" alt="Gitpod">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-21T05:46:44.000Z">2019-11-21</time></div>
                    <a href="/2019/11/21/gitpod/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Gitpod</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/20/PythonRobotics/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/20/6090d560-0b82-11ea-9a59-8136f50345cc.png" alt="PythonRobotics">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-20T10:41:02.000Z">2019-11-20</time></div>
                    <a href="/2019/11/20/PythonRobotics/" class="title has-link-black-ter is-size-6 has-text-weight-normal">PythonRobotics</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/19/sqlflow/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/19/6052aa40-0ada-11ea-888e-f9f900c5a0f9.png" alt="赋予 SQL AI 能力 SQLFlow">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-19T14:07:53.000Z">2019-11-19</time></div>
                    <a href="/2019/11/19/sqlflow/" class="title has-link-black-ter is-size-6 has-text-weight-normal">赋予 SQL AI 能力 SQLFlow</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/人工智能/">人工智能</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right is-sticky">
    
        
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2019/11/23/flash-crack/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/23/c7b6b780-0e04-11ea-92ef-97d48f79b822.png" alt="Flash的破解与加密(附flash破解工具)">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-23T15:19:24.000Z">2019-11-23</time></div>
                    <a href="/2019/11/23/flash-crack/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Flash的破解与加密(附flash破解工具)</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/22/inspire-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/22/55e1b850-0d12-11ea-bfb0-97cf8ad096e4.png" alt="INSPIRE 2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-22T10:24:48.000Z">2019-11-22</time></div>
                    <a href="/2019/11/22/inspire-2/" class="title has-link-black-ter is-size-6 has-text-weight-normal">INSPIRE 2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/生活/">生活</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/21/gitpod/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/21/1fa463f0-0c22-11ea-b732-8394f2c36e81.png" alt="Gitpod">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-21T05:46:44.000Z">2019-11-21</time></div>
                    <a href="/2019/11/21/gitpod/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Gitpod</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/20/PythonRobotics/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/20/6090d560-0b82-11ea-9a59-8136f50345cc.png" alt="PythonRobotics">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-20T10:41:02.000Z">2019-11-20</time></div>
                    <a href="/2019/11/20/PythonRobotics/" class="title has-link-black-ter is-size-6 has-text-weight-normal">PythonRobotics</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/文章/">文章</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/11/19/sqlflow/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/2019/11/19/6052aa40-0ada-11ea-888e-f9f900c5a0f9.png" alt="赋予 SQL AI 能力 SQLFlow">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-19T14:07:53.000Z">2019-11-19</time></div>
                    <a href="/2019/11/19/sqlflow/" class="title has-link-black-ter is-size-6 has-text-weight-normal">赋予 SQL AI 能力 SQLFlow</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/人工智能/">人工智能</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Time" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 times&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_uv">
                共<span id="busuanzi_value_site_uv">0</span>个访客
                </span>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="https://github.com/hsutimes/hsutimes.github.io">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>

<script>
var IcarusThemeSettings = {
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>



    
    
<script src="/js/animation.js"></script>

    
    
<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>

    
    
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>

    
    <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>
    
    
<a id="back-to-top" title="回到顶端" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>

    
    
    
    
    
    
    
    
    
    
    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>